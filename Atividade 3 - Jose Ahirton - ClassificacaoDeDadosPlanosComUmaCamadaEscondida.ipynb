{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de Dados Planares com uma camada escondida\n",
    "\n",
    "Bem-vindo a tarefa 3. Está na hora de construir a sua primeira rede neural, a qual conterá uma camada escondida. Você verá uma grande diferença entre este modelo e o modelo utilizando regressão logística.  \n",
    "\n",
    "**Você irá aprender:**\n",
    "- Implementar uma rede neural para classificação entre 2 classes com uma única camada escondida\n",
    "- Utilizar nós com uma função de ativação não-linear, como a tanh. \n",
    "- Computa a função de perda utilizando entropia cruzada. \n",
    "- Implementar propagação para frente e para trás.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Pacotes ##\n",
    "\n",
    "Primeiro vamos importar todos os pacotes que você irá utilizar nesta tarefa. \n",
    "- [numpy](www.numpy.org) é o pacote de computação científica do Python.\n",
    "- [sklearn](http://scikit-learn.org/stable/) possui ferramentas simples e eficientes para data mining e análise de dados. \n",
    "- [matplotlib](http://matplotlib.org) é uma biblioteca para plotar gráficos em Python.\n",
    "- testCases apresenta alguns exemplos de teste para verificar a implementação de funções.\n",
    "- planar_utils apresenta várias funções uteis para esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar Pacotes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from testCases_v2 import *\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from planar_utils import plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1) # define um valor de semente para consistência dos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Base de dados ##\n",
    "\n",
    "Primeiro vamos carregar a base de dados que será utilizada nesta tarefa. O código na célula abaixo irá carregar a \"flor\" uma base de dados com duas classes nas variáveis `X` e `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_planar_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a base de dados utilizando a matplotlib. Os dados lembram uma \"flor\" com alguns pontos vermelhos (classificação y=0) e alguns pontos azuis (y=1). Sua tarefa é construir um modelo que se ajuste a estes dados.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize os dados:\n",
    "plt.scatter(X[0, :], X[1, :], c=Y[0,:], s=40, cmap=plt.cm.Spectral);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você tem:\n",
    "    - um array (matrix) numpy, X, que contém os valores das características (x1, x2)\n",
    "    - um array (vetor) numpy, Y, que contém a classificação (vermelha:0, azul:1).\n",
    "\n",
    "Vamos primeiro obter uma melhor noção sobre estes dados. \n",
    "\n",
    "**Exercício**: Quantos exemplos de treinamento existem? Além disso, qual é o `formato` das variáveis `X` e `Y`? \n",
    "\n",
    "**Dica**: Como você determina o formato de um array numpy? [(ajuda)](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INICIE O SEU CÓDIGO AQUI ### (≈ 3 linhas de código)\n",
    "\n",
    "\n",
    "                # tamanho do conjunto de treinamento\n",
    "### TÉRMINO DO CÓDIGO ###\n",
    "\n",
    "print ('O formato de X é: ' + str(shape_X))\n",
    "print ('O formato de Y é: ' + str(shape_Y))\n",
    "print ('Existem m = %d exemplos no conjunto de treinamento!' % (m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "       \n",
    "<table style=\"width:20%\">\n",
    "  \n",
    "  <tr>\n",
    "    <td>**formato de X**</td>\n",
    "    <td> (2, 400) </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**formato de Y**</td>\n",
    "    <td>(1, 400) </td> \n",
    "  </tr>\n",
    "  \n",
    "    <tr>\n",
    "    <td>**m**</td>\n",
    "    <td> 400 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Regressão Logística Simples\n",
    "\n",
    "Antes de construir uma rede neural completa, vamos primeiro ver como a regressão logística se sai neste problema. Você poderia utilizar a função pronta sklearn para fazer isto. Execute o código abaixo para treinar uma regressão logística com a base de dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar um classificador com regressão logística\n",
    "clf = sklearn.linear_model.LogisticRegressionCV();\n",
    "clf.fit(X.T, Y.T);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível agora plotar a linha de decisão deste modelo executando o código abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotar a linha de decisão da regressão logística\n",
    "plot_decision_boundary(lambda x: clf.predict(x), X, Y)\n",
    "plt.title(\"Regressão Logística\")\n",
    "\n",
    "# Imprimir precisão\n",
    "LR_predictions = clf.predict(X.T)\n",
    "print ('A precisão da regressão logística é: %d ' % float((np.dot(Y,LR_predictions) + np.dot(1-Y,1-LR_predictions))/float(Y.size)*100) +\n",
    "       '% ' + \"(porcentagem de pontos classificados corretamente)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "\n",
    "<table style=\"width:20%\">\n",
    "  <tr>\n",
    "    <td>**Precisão**</td>\n",
    "    <td> 47% </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretação**: O conjunto de dados não é linearmente separável, logo, regressão logística não vai apresentar um bom desempenho. Espera-se que a rede neural seja bem melhor. Vamos experimentar! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Modelo de Rede Neural\n",
    "\n",
    "Regessão logística não funcionou bem com a base de dados \"flor\". Vamos treinar uma Rede Neural com uma única camada escondida e ver como ela se sai. \n",
    "\n",
    "**Este é o modelo**:\n",
    "<img src=\"images/classification_kiank.png\" style=\"width:600px;height:300px;\">\n",
    "\n",
    "**Matematicamente**:\n",
    "\n",
    "Para um exemplo $x^{(i)}$:\n",
    "$$z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1] (i)}\\tag{1}$$ \n",
    "$$a^{[1] (i)} = \\tanh(z^{[1] (i)})\\tag{2}$$\n",
    "$$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2] (i)}\\tag{3}$$\n",
    "$$\\hat{y}^{(i)} = a^{[2] (i)} = \\sigma(z^{ [2] (i)})\\tag{4}$$\n",
    "$$y^{(i)}_{prediction} = \\begin{cases} 1 & \\mbox{if } a^{[2](i)} > 0.5 \\\\ 0 & \\mbox{otherwise } \\end{cases}\\tag{5}$$\n",
    "\n",
    "Dada a previsão sobre todos os exemplos é possível determinar o custo $J$ da seguinte forma: \n",
    "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large\\left(\\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right)  \\large  \\right) \\small \\tag{6}$$\n",
    "\n",
    "**Lembre-se**: A metodologia geral para construir uma Rede Neural é: \n",
    "    1. Definir a estrutura da rede neural ( # de nós de entrada,  # de nós escondidos, etc). \n",
    "    2. Inicializar os parâmetros do modelo\n",
    "    3. Loop:\n",
    "        - Implementar propagação para frente\n",
    "        - Computar perda\n",
    "        - Implementar propagação para trás e determinar os gradientes\n",
    "        - Atualizar os parâmetros (gradiente descendente)\n",
    "\n",
    "Geralmente se constroem funções auxiliares par computar as etapas 1-3 e então criamos uma função modelo composta das funções auxiliares que chamamos de `modelo_rn()`. Uma vez construído o modelo `modelo_rn()` e aprendido os parâmetros corretamente, é possível realizar previsões sobre dados novos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - Definindo a estrutura de uma rede neural ####\n",
    "\n",
    "**Exercício**: Defina três variáveis:\n",
    "    - n_x: o tamanho da camada de entrada\n",
    "    - n_h: o tamanho da camada escondida (ajuste este valor para 4) \n",
    "    - n_y: o tamanho da camada de saída\n",
    "\n",
    "**Dica**: Use o formato de X e Y para encontrar n_x e n_y. Defina o tamanho da camada escondida como 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: Tamanho_Camadas\n",
    "\n",
    "def Tamanho_Camadas(X, Y):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    X -- dados de entrada no formato (tamanho da entrada, número de exemplos)\n",
    "    Y -- classificação no formato (tamanho da saída, número de exemplos)\n",
    "    \n",
    "    Retorna:\n",
    "    n_x -- o tamanho da camada de entrada\n",
    "    n_h -- o tamanho da camada escondida\n",
    "    n_y -- o tamanho da camada de saída\n",
    "    \"\"\"\n",
    "    ### INICIE O SEU CÓDIGO AQUI ### (≈ 3 linhas de código)\n",
    "                           # tamanho da camada de entrada\n",
    "    \n",
    "                         # tamanho da camada de saída\n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    return (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_assess, Y_assess = layer_sizes_test_case()\n",
    "(n_x, n_h, n_y) = Tamanho_Camadas(X_assess, Y_assess)\n",
    "print(\"O tamanho da camada de entrada é: n_x = \" + str(n_x))\n",
    "print(\"O tamanho da camada escondida é: n_h = \" + str(n_h))\n",
    "print(\"O tamanho da camada de saída é: n_y = \" + str(n_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saida Esperada** (estes não são os tamanhos que você irá utilizar na sua rede neural, eles foram utilizados aqui apenas para testar o seu código).\n",
    "\n",
    "<table style=\"width:20%\">\n",
    "  <tr>\n",
    "    <td>**n_x**</td>\n",
    "    <td> 5 </td> \n",
    "  </tr>\n",
    "  \n",
    "    <tr>\n",
    "    <td>**n_h**</td>\n",
    "    <td> 4 </td> \n",
    "  </tr>\n",
    "  \n",
    "    <tr>\n",
    "    <td>**n_y**</td>\n",
    "    <td> 2 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Inicialização dos parâmetros do modelo ####\n",
    "\n",
    "**Exercício**: Implemente a função `inicializar_parametros()`.\n",
    "\n",
    "**Instruções**:\n",
    "- Tenha a certeza de que o tamanho das matrizes/vetores de inicialização estão corretos. Reveja a rede neural da figura acima caso ache necessário.\n",
    "- Inicialize as matrizes de peso com valores aleatórios. \n",
    "    - Utilize: `np.random.randn(a,b) * 0.01` para criar uma matriz aleatória no formato (a,b).\n",
    "- Inicialize o vetor de bias com zeros. \n",
    "    - Utilize: `np.zeros((a,b))` para criar uma matriz de zeros no formato (a,b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: inicializar_parametros\n",
    "\n",
    "def inicializar_parametros(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    n_x -- número de nós na camada de entrada\n",
    "    n_h -- número de nós na camada escondida\n",
    "    n_y -- número de nós na camada de saída\n",
    "    \n",
    "    Retorna:\n",
    "    params -- um dicionário python contendo:\n",
    "                    W1 -- matriz de pesos no formato (n_h, n_x)\n",
    "                    b1 -- vetor bias no formato (n_h, 1)\n",
    "                    W2 -- matriz de pesos no formato (n_y, n_h)\n",
    "                    b2 -- vetor bias no formato (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(2) # definimos a semente do gerador de números aleatórios para comparar resultados.\n",
    "    \n",
    "    ### INICIE O SEU CÓDIGO AQUI ### (≈ 4 linhas de código)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    # verifica os formatos do que foi gerado\n",
    "    assert (W1.shape == (n_h, n_x))\n",
    "    assert (b1.shape == (n_h, 1))\n",
    "    assert (W2.shape == (n_y, n_h))\n",
    "    assert (b2.shape == (n_y, 1))\n",
    "    #cria o dicionário\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x, n_h, n_y = initialize_parameters_test_case()\n",
    "\n",
    "parameters = inicializar_parametros(n_x, n_h, n_y)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "\n",
    "<table style=\"width:90%\">\n",
    "  <tr>\n",
    "    <td>**W1**</td>\n",
    "    <td> [[-0.00416758 -0.00056267]\n",
    " [-0.02136196  0.01640271]\n",
    " [-0.01793436 -0.00841747]\n",
    " [ 0.00502881 -0.01245288]] </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**b1**</td>\n",
    "    <td> [[ 0.]\n",
    " [ 0.]\n",
    " [ 0.]\n",
    " [ 0.]] </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**W2**</td>\n",
    "    <td> [[-0.01057952 -0.00909008  0.00551454  0.02292208]]</td> \n",
    "  </tr>\n",
    "  \n",
    "\n",
    "  <tr>\n",
    "    <td>**b2**</td>\n",
    "    <td> [[ 0.]] </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - O Loop ####\n",
    "\n",
    "**Exercício**: Implemente `propagação_para_frente()`.\n",
    "\n",
    "**Instruções**:\n",
    "- Veja acima a representação matemática do seu classificador.\n",
    "- Utilize a função `sigmoid()`. Ela está pré-definida (importada) neste notebook.\n",
    "- Utilize a função `np.tanh()`. Ela faz parte da biblioteca numpy.\n",
    "- Implemente as seguintes etapas:\n",
    "    1. Recupere cada matriz/vetor de parâmetros do dicionário \"parameters\" (que é a saída da função `inicializar_parametros()`) usando `parametros[\"..\"]`.\n",
    "    2. Implemente a propagação para frente. Determine $Z^{[1]}, A^{[1]}, Z^{[2]}$ and $A^{[2]}$ (o vetor com todas as previsões sobre todos os exemplos do conjunto de treinamento).\n",
    "- Os valores necessários para a propagação para trás serão armazenados na \"`cache`\". A `cache` será passada como entrada da função de propagação para trás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: propagacao_para_frente\n",
    "\n",
    "def propagacao_para_frente(X, parametros):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    X -- dados de entrada no tamanho (n_x, m)\n",
    "    parametros -- dicionário python contendo os parâmetros (saída da função de inicialização)\n",
    "    \n",
    "    Retornas:\n",
    "    A2 -- a saída da função sigmoid da segunda ativação\n",
    "    cache -- um dicionário contendo \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
    "    \"\"\"\n",
    "    # Recupere cada parâmetro do dicionário de parametros\n",
    "    ### INICIE O SEU CÓDIGO AQUI ### (≈ 4 linhas de código)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "       \n",
    "    # Implemente a propagação para frente para calcular A2 (probabilidades)\n",
    "    ### INICIE O SEU CÓDIGO AQUI ### (≈ 4 linhas de código)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    # verifica o formato de A2\n",
    "    assert(A2.shape == (1, X.shape[1]))\n",
    "    # cria o dicionário de saída\n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_assess, parametros = forward_propagation_test_case()\n",
    "A2, cache = propagacao_para_frente(X_assess, parametros)\n",
    "\n",
    "# Nota: neste caso é utilizada a média somente para garantir que as saídas são compatíveis. \n",
    "print(np.mean(cache['Z1']) ,np.mean(cache['A1']),np.mean(cache['Z2']),np.mean(cache['A2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "<table style=\"width:50%\">\n",
    "  <tr>\n",
    "    <td> 0.262818640198 0.091999045227 -1.30766601287 0.212877681719 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que você determinou o valor de $A^{[2]}$ (na variável \"`A2`\" do Python), que contém $a^{[2](i)}$ para cada exemplo, você pode determinar a função de custo da seguinte forma:\n",
    "\n",
    "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large{(} \\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right) \\large{)} \\small\\tag{13}$$\n",
    "\n",
    "**Exerc;icio**: Implemente `computar_custo()` para determinar o valor do custo $J$.\n",
    "\n",
    "**Instruções**:\n",
    "- Existem diversas formas de se implementar a perda por entropia cruzada. Para ajudá-lo, mostramos abaixo como ela poderia ser implementada.\n",
    "$- \\sum\\limits_{i=0}^{m}  y^{(i)}\\log(a^{[2](i)})$:\n",
    "```python\n",
    "logprobs = np.multiply(np.log(A2),Y)\n",
    "cost = - np.sum(logprobs)                # não é necessário fazer um loop!\n",
    "```\n",
    "\n",
    "(voce pode utilizar tanto o `np.multiply()` e então `np.sum()` ou diretamente `np.dot()`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: computar_custo\n",
    "\n",
    "def computar_custo(A2, Y, parametros):\n",
    "    \"\"\"\n",
    "    Computa o custo por entropia cruzada mostrado na equação (13)\n",
    "    \n",
    "    Argumentos:\n",
    "    A2 -- O valor de saída da segunda ativação no formato (1, número de exemplos)\n",
    "    Y --  vetor de classificação real no formato (1, número de exemplos)\n",
    "    parametros -- dicionário python contendo os parâmetros W1, b1, W2 e b2\n",
    "    \n",
    "    Retorna:\n",
    "    custot -- o custo por entropis cruzada de acordo com a equação (13)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1] # número de exemplos\n",
    "\n",
    "    # Computação do custo por entropia cruzada\n",
    "    ### INICIE O SEU CÓDIGO AQUI ### (≈ 2 linhas de código)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "    cost = np.squeeze(cost)     # verifique que as dimensões estão corretas. \n",
    "                                # por exemplo, transforme [[17]] em 17 \n",
    "    assert(isinstance(cost, float))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2, Y_assess, parameters = compute_cost_test_case()\n",
    "\n",
    "print(\"custo = \" + str(computar_custo(A2, Y_assess, parameters)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "<table style=\"width:20%\">\n",
    "  <tr>\n",
    "    <td>**custo**</td>\n",
    "    <td> 0.693058761... </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando a cache computada durante a propagação para frente, é possível determinar a propagação para trás.\n",
    "\n",
    "**Exercício**: Implemente a função `propagação_para_tras()`.\n",
    "\n",
    "**Instruções**:\n",
    "A propagação para trás geralmente é a mais difícil de ser implementada em deep learning por ser mais matemática. Para ajudá-lo mostramos abaixo a propagação para trás. Você deve utilizar as seis equações mostradas no lado direito pois estamos utilizando vetorização.   \n",
    "\n",
    "<img src=\"images/grad_summary.png\" style=\"width:600px;height:300px;\">\n",
    "\n",
    "<!--\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } = \\frac{1}{m} (a^{[2](i)} - y^{(i)})$\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial W_2 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } a^{[1] (i) T} $\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial b_2 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)}}}$\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} } =  W_2^T \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } * ( 1 - a^{[1] (i) 2}) $\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial W_1 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} }  X^T $\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} _i }{ \\partial b_1 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)}}}$\n",
    "\n",
    "- Note que $*$ indica multiplicação elemento a elemento.\n",
    "- A notação a ser utilizada é comum na codificação de deep learning: \n",
    "    - dW1 = $\\frac{\\partial \\mathcal{J} }{ \\partial W_1 }$\n",
    "    - db1 = $\\frac{\\partial \\mathcal{J} }{ \\partial b_1 }$\n",
    "    - dW2 = $\\frac{\\partial \\mathcal{J} }{ \\partial W_2 }$\n",
    "    - db2 = $\\frac{\\partial \\mathcal{J} }{ \\partial b_2 }$\n",
    "    \n",
    "!-->\n",
    "\n",
    "- Dicas:\n",
    "    - Para computar dZ1 você precisa computar $g^{[1]'}(Z^{[1]})$. Como $g^{[1]}(.)$ é a função de ativação tanh, se $a = g^{[1]}(z)$ então $g^{[1]'}(z) = 1-a^2$. E você pode determinar \n",
    "    $g^{[1]'}(Z^{[1]})$ usando `(1 - np.power(A1, 2))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: propagação_para_tras\n",
    "\n",
    "def propagacao_para_tras(parametros, cache, X, Y):\n",
    "    \"\"\"\n",
    "    Implemente a propagação para trás usando as instruções acima.\n",
    "    \n",
    "    Argumentos:\n",
    "    parametros -- dicionário python contendo os parâmetros \n",
    "    cache -- um dicionário contendo \"Z1\", \"A1\", \"Z2\" e \"A2\".\n",
    "    X -- dados de entrada no formato (2, numero de exemplos)\n",
    "    Y -- vetor com a classificação correta de cada exemplo no formato (1, numero de exemplos)\n",
    "    \n",
    "    Retorna:\n",
    "    grads -- um dicionário python contendo os gradientes com relação a cada parâmetro\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # 1) recupere as metrizes W1 e W2 dos parametros.\n",
    "    ### INICIE O SEU CÓDIGO AQUI ### (≈ 2 linhas de código)\n",
    "    \n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "        \n",
    "    # 2) recupere A1 e A2 do dicionario cache. \n",
    "    ### INICIE O SEU CÓDIGO AQUI ### (≈ 2 linhas de código)\n",
    "    \n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "    # Propagacao para tras: determine dW1, db1, dW2, db2. \n",
    "    ### INICIE O SEU CÓDIGO AQUI ### (≈ 6 linhas de código, correspondendo às 6 equações acima)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters, cache, X_assess, Y_assess = backward_propagation_test_case()\n",
    "\n",
    "grads = propagacao_para_tras(parameters, cache, X_assess, Y_assess)\n",
    "print (\"dW1 = \"+ str(grads[\"dW1\"]))\n",
    "print (\"db1 = \"+ str(grads[\"db1\"]))\n",
    "print (\"dW2 = \"+ str(grads[\"dW2\"]))\n",
    "print (\"db2 = \"+ str(grads[\"db2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "\n",
    "\n",
    "\n",
    "<table style=\"width:80%\">\n",
    "  <tr>\n",
    "    <td>**dW1**</td>\n",
    "    <td> [[ 0.00301023 -0.00747267]\n",
    " [ 0.00257968 -0.00641288]\n",
    " [-0.00156892  0.003893  ]\n",
    " [-0.00652037  0.01618243]] </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**db1**</td>\n",
    "    <td>  [[ 0.00176201]\n",
    " [ 0.00150995]\n",
    " [-0.00091736]\n",
    " [-0.00381422]] </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**dW2**</td>\n",
    "    <td> [[ 0.00078841  0.01765429 -0.00084166 -0.01022527]] </td> \n",
    "  </tr>\n",
    "  \n",
    "\n",
    "  <tr>\n",
    "    <td>**db2**</td>\n",
    "    <td> [[-0.16655712]] </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício**: Implemente a regra para atualizar os parâmetros. Use gradiente descendente. Você deve utilizar (dW1, db1, dW2, db2) para atualizar (W1, b1, W2, b2).\n",
    "\n",
    "**Regra Geral do Gradiente Descendente**: $ \\theta = \\theta - \\alpha \\frac{\\partial J }{ \\partial \\theta }$ onde $\\alpha$ é a taxa de aprendizado e $\\theta$ representa um parâmetro.\n",
    "\n",
    "**Ilustração**: O algoritmo de gradiente descendente com uma boa taxa de de aprendizado (convergendo) e uma taxa de aprendizado ruim (divergendo). Imagens, cortesia de Adam Harley.\n",
    "\n",
    "<img src=\"images/sgd.gif\" style=\"width:400;height:400;\"> <img src=\"images/sgd_bad.gif\" style=\"width:400;height:400;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: atualizar_parametros\n",
    "\n",
    "def atualizar_parametros(parametros, grads, learning_rate = 1.2):\n",
    "    \"\"\"\n",
    "    Atualizacao de parametros utilizando a regra de gradiente descendente dada acima.\n",
    "    \n",
    "    Argumentos:\n",
    "    parametros -- dicionario python contendo os parametros.  \n",
    "    grads -- dicionario python contendo os gradientes. \n",
    "    \n",
    "    Retorna:\n",
    "    parametros -- dicionario python contendo os valores de atualizacao dos parametros. \n",
    "    \"\"\"\n",
    "    # 1) recupere cada parametro do dicionario parametros\n",
    "    ### INICIE O SEU CÓDIGO AQUI ### (≈ 4 linhas de código)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "    # 2) Recupere cada gradiente do dicionario grads\n",
    "    ### INICIE O SEU CÓDIGO AQUI ### (≈ 4 linhas de código)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "    # 3) regra de atualizacao para cada parametro\n",
    "    ### INICIE O SEU CÓDIGO AQUI ### (≈ 4 linhas de código)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "    parametros = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parameters, grads = update_parameters_test_case()\n",
    "parameters = atualizar_parametros(parameters, grads)\n",
    "\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "\n",
    "\n",
    "<table style=\"width:80%\">\n",
    "  <tr>\n",
    "    <td>**W1**</td>\n",
    "    <td> [[-0.00643025  0.01936718]\n",
    " [-0.02410458  0.03978052]\n",
    " [-0.01653973 -0.02096177]\n",
    " [ 0.01046864 -0.05990141]]</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**b1**</td>\n",
    "    <td> [[ -1.02420756e-06]\n",
    " [  1.27373948e-05]\n",
    " [  8.32996807e-07]\n",
    " [ -3.20136836e-06]]</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**W2**</td>\n",
    "    <td> [[-0.01041081 -0.04463285  0.01758031  0.04747113]] </td> \n",
    "  </tr>\n",
    "  \n",
    "\n",
    "  <tr>\n",
    "    <td>**b2**</td>\n",
    "    <td> [[ 0.00010457]] </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 - Integrar as partes 4.1, 4.2 e 4.3 no modelo_rn() ####\n",
    "\n",
    "**Exercício**: Construa o modelo de rede neural `modelo_rn()`.\n",
    "\n",
    "**Instruções**: O modelo de rede neural deve utilizar as  funções definidas previamente na ordem correta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: modelo_rn\n",
    "\n",
    "def modelo_rn(X, Y, n_h, num_iterations = 10000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    X -- dados de entrada no formato (2, numero de exemplos)\n",
    "    Y -- classificação correta no formato (1, numero de exemplos)\n",
    "    n_h -- tamanho da camada escondida (número de nós)\n",
    "    num_iterations -- Número de interações no loop do gradiente descendente\n",
    "    print_cost -- se True, imprime o valor do custo a cada 1000 interacoes\n",
    "    \n",
    "    Retorna:\n",
    "    parametros -- parametros aprendidos pelo modelo. Eles podem ser utilizados para prever saídas em entradas novas.\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    n_x = Tamanho_Camadas(X, Y)[0]\n",
    "    n_y = Tamanho_Camadas(X, Y)[2]\n",
    "    \n",
    "    # Inicializacao de parametros, então, recupere W1, b1, W2, b2. Entradas: \"n_x, n_h, n_y\". Saídas = \"W1, b1, W2, b2, \n",
    "    # parametros\".\n",
    "    ### INICIE O SEU CÓDIGO AQUI ### (≈ 5 linhas de código)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "    # Loop (gradiente descendente)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "         \n",
    "        ### INICIE O SEU CÓDIGO AQUI ### (≈ 4 linhas de código)\n",
    "        # propagacao para frente. Entradas: \"X, parametros\". Saídas: \"A2, cache\".\n",
    "        \n",
    "        \n",
    "        # funcao de custo. Entradas: \"A2, Y, parametros\". Saída: \"custo\".\n",
    "        \n",
    " \n",
    "        # propagacao para trás. Entradas: \"parametros, cache, X, Y\". Saídas: \"grads\".\n",
    "        \n",
    " \n",
    "        # Atualizacao dos parametros utilizando Gradiente descendente. Entradas: \"parametros, grads\". Saída: \"parametros\".\n",
    "        \n",
    "        \n",
    "        ### TÉRMINO DO CÓDIGO ###\n",
    "        \n",
    "        # Imprimir  o custo a cada 1000 interacoes\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Custo após interação %i: %f\" %(i, custo))\n",
    "\n",
    "    return parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_assess, Y_assess = nn_model_test_case()\n",
    "parameters = modelo_rn(X_assess, Y_assess, 4, num_iterations=10000, print_cost=True)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "\n",
    "<table style=\"width:90%\">\n",
    "\n",
    "<tr> \n",
    "    <td> \n",
    "        **custo após a interação 0**\n",
    "    </td>\n",
    "    <td> \n",
    "        0.692739\n",
    "    </td>\n",
    "</tr>\n",
    "\n",
    "<tr> \n",
    "    <td> \n",
    "        <center> $\\vdots$ </center>\n",
    "    </td>\n",
    "    <td> \n",
    "        <center> $\\vdots$ </center>\n",
    "    </td>\n",
    "</tr>\n",
    "\n",
    "  <tr>\n",
    "    <td>**W1**</td>\n",
    "    <td> [[-0.65848169  1.21866811]\n",
    " [-0.76204273  1.39377573]\n",
    " [ 0.5792005  -1.10397703]\n",
    " [ 0.76773391 -1.41477129]]</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**b1**</td>\n",
    "    <td> [[ 0.287592  ]\n",
    " [ 0.3511264 ]\n",
    " [-0.2431246 ]\n",
    " [-0.35772805]] </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**W2**</td>\n",
    "    <td> [[-2.45566237 -3.27042274  2.00784958  3.36773273]] </td> \n",
    "  </tr>\n",
    "  \n",
    "\n",
    "  <tr>\n",
    "    <td>**b2**</td>\n",
    "    <td> [[ 0.20459656]] </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Prevendo\n",
    "\n",
    "**Exercício**: Use o seu modelo para prever saídas de novas entradas utilizando prever().\n",
    "Use a propagação para frente para prever os resultados.\n",
    "\n",
    "**Lembre-se**: prever = $y_{previsto} = \\mathbb 1 \\text{{ativação > 0.5}} = \\begin{cases}\n",
    "      1 & \\text{se}\\ ativação > 0.5 \\\\\n",
    "      0 & \\text{caso contrário}\n",
    "    \\end{cases}$  \n",
    "    \n",
    "Como exemplo, se você ajustar as entradas de uma matriz X para 0 e 1 baseado no \"threshold\" você faria: ```X_new = (X > threshold)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: prever\n",
    "\n",
    "def prever(parametros, X):\n",
    "    \"\"\"\n",
    "    Utilizando os parâmetros aprendidos, prever uma classe para cada exemplo na entrada X.\n",
    "    \n",
    "    Argumentos:\n",
    "    parâmetros -- dicionário python contendo seus parâmetros \n",
    "    X -- Dados de entrada no formato (n_x, m)\n",
    "    \n",
    "    Retorna\n",
    "    previsoes -- vetor de previsões paa nosso modelo (vermelho: 0 / azul: 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Computa as probabilidades usando propagação para frente, e classifica em 0/1 usando 0.5 como threshold.\n",
    "    ### INICIE O SEU CÓDIGO AQUI ### (≈ 2 linhas de código)\n",
    "    \n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "    return previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters, X_assess = predict_test_case()\n",
    "\n",
    "predictions = prever(parameters, X_assess)\n",
    "print(\"média prevista = \" + str(np.mean(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**: \n",
    "\n",
    "\n",
    "<table style=\"width:40%\">\n",
    "  <tr>\n",
    "    <td>**média prevista**</td>\n",
    "    <td> 0.666666666667 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Está na hora de executar o seu modelo e ver como ele desempenha em um conjunto de dados planares. Execute o código a seguir para testar seu modelo com uma única camada escondida contendo $n_h$ nós."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Construa um modelo com n_h nós na camada escondida \n",
    "parametros = modelo_rn(X, Y, n_h = 4, num_iterations = 10000, print_cost=True)\n",
    "\n",
    "# Plotar a borda de limites no plano\n",
    "plot_decision_boundary(lambda x: prever(parametros, x.T), X, Y)\n",
    "plt.title(\"Borda de decisão para uma camada escondida de tamanho \" + str(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "\n",
    "<table style=\"width:40%\">\n",
    "  <tr>\n",
    "    <td>**Custo após interação 9000**</td>\n",
    "    <td> 0.218607 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print accuracy\n",
    "predictions = prever(parametros, X)\n",
    "print ('Precisao: %d' % float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**: \n",
    "\n",
    "<table style=\"width:15%\">\n",
    "  <tr>\n",
    "    <td>**Precisão**</td>\n",
    "    <td> 90% </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A precisão está realmente alta se comparada com a regressão logística. O modelo aprendeu o padrão das petalas da flor! Redes neurais são capazes de aprender limites de decisão altamente não-lineares, diferente de=a regressão logística. \n",
    "\n",
    "Vamos tentar diferentes números de nós na camada escondida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 -  Ajustando o número de nós na camada escondida (opcional) ###\n",
    "\n",
    "Execute o código abaixo. Ele deve levar entre 2 e 3 minutos. Você deve observar ao final comportamentos diferentes do modelo, dependendo do número de nós na camada escondida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Isto pode levar uns 2 minutos para ser executado\n",
    "\n",
    "plt.figure(figsize=(16, 32))\n",
    "hidden_layer_sizes = [1, 2, 3, 4, 5, 20, 50]\n",
    "for i, n_h in enumerate(hidden_layer_sizes):\n",
    "    plt.subplot(5, 2, i+1)\n",
    "    plt.title('Número de nós na camada escondida %d' % n_h)\n",
    "    parameters = modelo_rn(X, Y, n_h, num_iterations = 5000)\n",
    "    plot_decision_boundary(lambda x: prever(parameters, x.T), X, Y)\n",
    "    predictions = prever(parameters, X)\n",
    "    accuracy = float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100)\n",
    "    print (\"Precisão para {} nós escondidos: {} %\".format(n_h, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretação**:\n",
    "- Quanto maior o modelo (com mais nós escondidos) mais fácil é o ajuste no conjunto de treinamento, até que, eventualmente, os modelos maiores se sobreajustam aos dados. \n",
    "- O melhor número de nós na camada escondida parece ser algo em torno de n_h = 5. Neste caso, a rede se ajusta aos dados e não apresenta sobreajuste.\n",
    "- Mais para frente vmos falar sobre regularizacao, que ajuda a utilizar modelos grandes (com n_h = 50) sem que ocorra o sobreajuste.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício opcional**:\n",
    "\n",
    "**Nota**: Lembre-se de salvar a tarefa e criar uma cópia para executar os exercícios opcionais. \n",
    "\n",
    "Alguns exercícios opcionais que você pode explorar para entender melhor as redes neurais: \n",
    "- O que ocorre se trocamos a função de ativação da tanh para a sigmoid ou a ReLu? \n",
    "- Como o modelo se comporta se alteramos a taxa de aprendizado?\n",
    "- O que ocorre se modificamos o conjunto de dados? (Veja a part 5 abaixo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "**Você Aprendeu:**\n",
    "- Construir uma rede neural completa com camada escondida.\n",
    "- Utilizar nós com comportamento não linear.\n",
    "- Implementar a propagação para frente e para trás e treinar uma rede neural.\n",
    "- Ver o impacto no modelo ao variar o número de nós na camada escondida, incluindo o sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Desempenho em outras bases de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Se quiser você pode rodar novamente o notebook todo (exceto a parte do conjunto de dados) para cada uma das bases de dados abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Bases de dados\n",
    "noisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure = load_extra_datasets()\n",
    "\n",
    "datasets = {\"noisy_circles\": noisy_circles,\n",
    "            \"noisy_moons\": noisy_moons,\n",
    "            \"blobs\": blobs,\n",
    "            \"gaussian_quantiles\": gaussian_quantiles}\n",
    "\n",
    "### INICIE O SEU CÓDIGO AQUI ### (escolha a sua base de dados)\n",
    "dataset = \n",
    "### TÉRMINO DO CÓDIGO ###\n",
    "\n",
    "X, Y = datasets[dataset]\n",
    "X, Y = X.T, Y.reshape(1, Y.shape[0])\n",
    "\n",
    "# fazr blobs binários\n",
    "if dataset == \"blobs\":\n",
    "    Y = Y%2\n",
    "\n",
    "# Visualizar os dados\n",
    "plt.scatter(X[0, :], X[1, :], c=Y[0,:], s=40, cmap=plt.cm.Spectral);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parabéns, você completou esta tarefa!\n",
    "\n",
    "Referências:\n",
    "- http://scs.ryerson.ca/~aharley/neural-networks/\n",
    "- http://cs231n.github.io/neural-networks-case-study/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "wRuwL",
   "launcher_item_id": "NI888"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
